{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8ba653a",
   "metadata": {},
   "source": [
    "# An√°lisis Exploratorio de Datos (EDA) - TalentPulse HR Data\n",
    "\n",
    "Este notebook realiza un an√°lisis exploratorio completo sobre los datos de recursos humanos procesados por el pipeline ETL. Incluye:\n",
    "\n",
    "- **An√°lisis descriptivo** de empleados, departamentos y m√©tricas clave\n",
    "- **Visualizaciones interactivas** para identificar patrones y tendencias\n",
    "- **Correlaciones** entre variables de desempe√±o, salario y antig√ºedad\n",
    "- **Insights de negocio** para la toma de decisiones en RRHH\n",
    "\n",
    "**Dataset**: Datos limpios y con features procesados por TalentPulse ETL Pipeline  \n",
    "**Registros**: 2,000,000 empleados  \n",
    "**Fecha**: Septiembre 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f88d2769",
   "metadata": {},
   "source": [
    "## 1. Configuraci√≥n e Importaci√≥n de Librer√≠as\n",
    "\n",
    "Configuramos el entorno e importamos las librer√≠as necesarias para an√°lisis y visualizaci√≥n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597f6017",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importaciones principales\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "\n",
    "# Configuraci√≥n de visualizaciones\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "# Configuraci√≥n de pandas para mostrar m√°s informaci√≥n\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)\n",
    "\n",
    "# Suprimir advertencias menores\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuraci√≥n de matplotlib\n",
    "plt.rcParams['font.size'] = 10\n",
    "plt.rcParams['axes.titlesize'] = 12\n",
    "plt.rcParams['axes.labelsize'] = 10\n",
    "plt.rcParams['xtick.labelsize'] = 9\n",
    "plt.rcParams['ytick.labelsize'] = 9\n",
    "plt.rcParams['legend.fontsize'] = 9\n",
    "\n",
    "print(\"‚úÖ Librer√≠as importadas correctamente\")\n",
    "print(f\"üìä Pandas versi√≥n: {pd.__version__}\")\n",
    "print(f\"üìà Numpy versi√≥n: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2beafda",
   "metadata": {},
   "source": [
    "## 2. Carga de Datos\n",
    "\n",
    "Cargamos el dataset procesado que incluye tanto los datos limpios como las features generadas por el pipeline ETL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f51d92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar dataset con features procesadas\n",
    "try:\n",
    "    # Intentar cargar datos con features primero\n",
    "    df_features = pd.read_csv('Data/processed/hr_with_features.csv')\n",
    "    df = df_features.copy()\n",
    "    print(\"‚úÖ Dataset con features cargado exitosamente\")\n",
    "    data_source = \"Con features\"\n",
    "except FileNotFoundError:\n",
    "    # Si no existe, cargar datos limpios b√°sicos\n",
    "    df = pd.read_csv('Data/processed/clean_hr.csv')\n",
    "    print(\"‚ö†Ô∏è Dataset b√°sico cargado (sin features)\")\n",
    "    data_source = \"B√°sico\"\n",
    "\n",
    "# Informaci√≥n general del dataset\n",
    "print(f\"\\nüìä Informaci√≥n del dataset ({data_source}):\")\n",
    "print(f\"   ‚Ä¢ Registros: {len(df):,}\")\n",
    "print(f\"   ‚Ä¢ Columnas: {len(df.columns)}\")\n",
    "print(f\"   ‚Ä¢ Memoria: {df.memory_usage(deep=True).sum() / 1024**2:.1f} MB\")\n",
    "\n",
    "# Mostrar primeras filas\n",
    "print(f\"\\nüîç Primeras 3 filas:\")\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df09ea8",
   "metadata": {},
   "source": [
    "## 3. An√°lisis Descriptivo General\n",
    "\n",
    "Exploramos la estructura y caracter√≠sticas principales del dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d103087",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Informaci√≥n detallada del DataFrame\n",
    "print(\"üìã INFORMACI√ìN T√âCNICA DEL DATASET\")\n",
    "print(\"=\" * 50)\n",
    "df.info()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"üìä ESTAD√çSTICAS DESCRIPTIVAS - Variables Num√©ricas\")\n",
    "print(\"=\" * 50)\n",
    "numeric_stats = df.describe()\n",
    "display(numeric_stats.round(2))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"üìù ESTAD√çSTICAS DESCRIPTIVAS - Variables Categ√≥ricas\")\n",
    "print(\"=\" * 50)\n",
    "categorical_stats = df.describe(include=['object', 'string'])\n",
    "if not categorical_stats.empty:\n",
    "    display(categorical_stats)\n",
    "else:\n",
    "    print(\"No hay variables categ√≥ricas en el dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad7ff19",
   "metadata": {},
   "source": [
    "## 4. An√°lisis de Distribuciones por Departamento\n",
    "\n",
    "Analizamos la composici√≥n de la organizaci√≥n por departamentos y sus caracter√≠sticas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eca55a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# An√°lisis por departamento\n",
    "dept_col = 'departamento' if 'departamento' in df.columns else 'Department'\n",
    "\n",
    "if dept_col in df.columns:\n",
    "    # Distribuci√≥n por departamento\n",
    "    dept_counts = df[dept_col].value_counts()\n",
    "    \n",
    "    # Crear figura con m√∫ltiples subgr√°ficos\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    fig.suptitle('üìä An√°lisis de Distribuci√≥n por Departamento', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # 1. Gr√°fico de barras - Cantidad por departamento\n",
    "    axes[0,0].bar(range(len(dept_counts)), dept_counts.values, color='skyblue', alpha=0.8)\n",
    "    axes[0,0].set_title('Empleados por Departamento')\n",
    "    axes[0,0].set_xticks(range(len(dept_counts)))\n",
    "    axes[0,0].set_xticklabels(dept_counts.index, rotation=45, ha='right')\n",
    "    axes[0,0].set_ylabel('N√∫mero de Empleados')\n",
    "    \n",
    "    # Agregar valores en las barras\n",
    "    for i, v in enumerate(dept_counts.values):\n",
    "        axes[0,0].text(i, v + max(dept_counts.values)*0.01, f'{v:,}', \n",
    "                      ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    # 2. Gr√°fico de pastel - Porcentaje por departamento\n",
    "    colors = plt.cm.Set3(np.linspace(0, 1, len(dept_counts)))\n",
    "    wedges, texts, autotexts = axes[0,1].pie(dept_counts.values, labels=dept_counts.index, \n",
    "                                           autopct='%1.1f%%', colors=colors, startangle=90)\n",
    "    axes[0,1].set_title('Distribuci√≥n Porcentual por Departamento')\n",
    "    \n",
    "    # 3. Top 10 departamentos\n",
    "    top_10_depts = dept_counts.head(10)\n",
    "    axes[1,0].barh(range(len(top_10_depts)), top_10_depts.values, color='lightcoral', alpha=0.8)\n",
    "    axes[1,0].set_title('Top 10 Departamentos')\n",
    "    axes[1,0].set_yticks(range(len(top_10_depts)))\n",
    "    axes[1,0].set_yticklabels(top_10_depts.index)\n",
    "    axes[1,0].set_xlabel('N√∫mero de Empleados')\n",
    "    \n",
    "    # 4. Estad√≠sticas de departamentos\n",
    "    axes[1,1].axis('off')\n",
    "    stats_text = f\"\"\"\n",
    "    üìà ESTAD√çSTICAS CLAVE\n",
    "    \n",
    "    Total Departamentos: {df[dept_col].nunique()}\n",
    "    Departamento m√°s grande: {dept_counts.index[0]}\n",
    "    ({dept_counts.iloc[0]:,} empleados)\n",
    "    \n",
    "    Departamento m√°s peque√±o: {dept_counts.index[-1]}\n",
    "    ({dept_counts.iloc[-1]:,} empleados)\n",
    "    \n",
    "    Promedio por departamento: {dept_counts.mean():.0f}\n",
    "    Mediana por departamento: {dept_counts.median():.0f}\n",
    "    \"\"\"\n",
    "    axes[1,1].text(0.1, 0.9, stats_text, transform=axes[1,1].transAxes, \n",
    "                   fontsize=11, verticalalignment='top', bbox=dict(boxstyle=\"round,pad=0.3\", \n",
    "                   facecolor=\"lightblue\", alpha=0.7))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Tabla resumen\n",
    "    print(\"\\nüìã RESUMEN POR DEPARTAMENTO:\")\n",
    "    print(\"-\" * 50)\n",
    "    dept_summary = pd.DataFrame({\n",
    "        'Empleados': dept_counts,\n",
    "        'Porcentaje': (dept_counts / len(df) * 100).round(1)\n",
    "    })\n",
    "    display(dept_summary.head(10))\n",
    "    \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Columna de departamento no encontrada en el dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86361754",
   "metadata": {},
   "source": [
    "## 5. An√°lisis Salarial Detallado\n",
    "\n",
    "Exploramos las distribuciones salariales y su relaci√≥n con otras variables organizacionales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52f140f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# An√°lisis salarial\n",
    "salary_col = 'salario_inr' if 'salario_inr' in df.columns else 'Salary_INR'\n",
    "\n",
    "if salary_col in df.columns:\n",
    "    # Crear figura con an√°lisis salarial\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "    fig.suptitle('üí∞ An√°lisis Salarial Completo', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # 1. Histograma de salarios\n",
    "    axes[0,0].hist(df[salary_col], bins=50, alpha=0.7, color='green', edgecolor='black')\n",
    "    axes[0,0].set_title('Distribuci√≥n de Salarios')\n",
    "    axes[0,0].set_xlabel('Salario (INR)')\n",
    "    axes[0,0].set_ylabel('Frecuencia')\n",
    "    axes[0,0].ticklabel_format(style='scientific', axis='x', scilimits=(0,0))\n",
    "    \n",
    "    # 2. Boxplot de salarios\n",
    "    axes[0,1].boxplot(df[salary_col], vert=True, patch_artist=True, \n",
    "                     boxprops=dict(facecolor='lightblue', alpha=0.7))\n",
    "    axes[0,1].set_title('Detecci√≥n de Outliers Salariales')\n",
    "    axes[0,1].set_ylabel('Salario (INR)')\n",
    "    axes[0,1].ticklabel_format(style='scientific', axis='y', scilimits=(0,0))\n",
    "    \n",
    "    # 3. Salarios por departamento (top 10)\n",
    "    if 'departamento' in df.columns or 'Department' in df.columns:\n",
    "        dept_col = 'departamento' if 'departamento' in df.columns else 'Department'\n",
    "        salary_by_dept = df.groupby(dept_col)[salary_col].mean().sort_values(ascending=False).head(10)\n",
    "        \n",
    "        axes[0,2].barh(range(len(salary_by_dept)), salary_by_dept.values, color='orange', alpha=0.8)\n",
    "        axes[0,2].set_title('Salario Promedio por Departamento (Top 10)')\n",
    "        axes[0,2].set_yticks(range(len(salary_by_dept)))\n",
    "        axes[0,2].set_yticklabels(salary_by_dept.index)\n",
    "        axes[0,2].set_xlabel('Salario Promedio (INR)')\n",
    "        axes[0,2].ticklabel_format(style='scientific', axis='x', scilimits=(0,0))\n",
    "    else:\n",
    "        axes[0,2].text(0.5, 0.5, 'Datos de departamento\\nno disponibles', \n",
    "                       ha='center', va='center', transform=axes[0,2].transAxes)\n",
    "        axes[0,2].set_title('Salarios por Departamento')\n",
    "    \n",
    "    # 4. Distribuci√≥n por cuartiles\n",
    "    q1 = df[salary_col].quantile(0.25)\n",
    "    q2 = df[salary_col].quantile(0.50)\n",
    "    q3 = df[salary_col].quantile(0.75)\n",
    "    \n",
    "    quartile_labels = ['Q1 (25%)', 'Q2 (50%)', 'Q3 (75%)', 'Q4 (100%)']\n",
    "    quartile_counts = [\n",
    "        (df[salary_col] <= q1).sum(),\n",
    "        ((df[salary_col] > q1) & (df[salary_col] <= q2)).sum(),\n",
    "        ((df[salary_col] > q2) & (df[salary_col] <= q3)).sum(),\n",
    "        (df[salary_col] > q3).sum()\n",
    "    ]\n",
    "    \n",
    "    axes[1,0].pie(quartile_counts, labels=quartile_labels, autopct='%1.1f%%', \n",
    "                 colors=['#ff9999', '#66b3ff', '#99ff99', '#ffcc99'], startangle=90)\n",
    "    axes[1,0].set_title('Distribuci√≥n por Cuartiles Salariales')\n",
    "    \n",
    "    # 5. Tendencia salarial (si hay datos de antig√ºedad)\n",
    "    if 'antiguedad_anos' in df.columns:\n",
    "        # Agrupar por a√±os de antig√ºedad\n",
    "        salary_by_tenure = df.groupby(df['antiguedad_anos'].round())[salary_col].mean()\n",
    "        axes[1,1].plot(salary_by_tenure.index, salary_by_tenure.values, \n",
    "                      marker='o', linewidth=2, markersize=6, color='purple')\n",
    "        axes[1,1].set_title('Salario Promedio vs Antig√ºedad')\n",
    "        axes[1,1].set_xlabel('A√±os de Antig√ºedad')\n",
    "        axes[1,1].set_ylabel('Salario Promedio (INR)')\n",
    "        axes[1,1].grid(True, alpha=0.3)\n",
    "        axes[1,1].ticklabel_format(style='scientific', axis='y', scilimits=(0,0))\n",
    "    else:\n",
    "        axes[1,1].text(0.5, 0.5, 'Datos de antig√ºedad\\nno disponibles', \n",
    "                       ha='center', va='center', transform=axes[1,1].transAxes)\n",
    "        axes[1,1].set_title('Salario vs Antig√ºedad')\n",
    "    \n",
    "    # 6. Estad√≠sticas salariales\n",
    "    axes[1,2].axis('off')\n",
    "    salary_stats = f\"\"\"\n",
    "    üìä ESTAD√çSTICAS SALARIALES\n",
    "    \n",
    "    Promedio: ‚Çπ{df[salary_col].mean():,.0f}\n",
    "    Mediana: ‚Çπ{df[salary_col].median():,.0f}\n",
    "    M√≠nimo: ‚Çπ{df[salary_col].min():,.0f}\n",
    "    M√°ximo: ‚Çπ{df[salary_col].max():,.0f}\n",
    "    \n",
    "    Desviaci√≥n Est√°ndar: ‚Çπ{df[salary_col].std():,.0f}\n",
    "    \n",
    "    Cuartiles:\n",
    "    Q1 (25%): ‚Çπ{q1:,.0f}\n",
    "    Q2 (50%): ‚Çπ{q2:,.0f}\n",
    "    Q3 (75%): ‚Çπ{q3:,.0f}\n",
    "    \n",
    "    Rango Intercuartil: ‚Çπ{q3-q1:,.0f}\n",
    "    \"\"\"\n",
    "    axes[1,2].text(0.1, 0.9, salary_stats, transform=axes[1,2].transAxes, \n",
    "                   fontsize=10, verticalalignment='top', \n",
    "                   bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"lightgreen\", alpha=0.7))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # An√°lisis de outliers salariales\n",
    "    IQR = q3 - q1\n",
    "    lower_bound = q1 - 1.5 * IQR\n",
    "    upper_bound = q3 + 1.5 * IQR\n",
    "    outliers = df[(df[salary_col] < lower_bound) | (df[salary_col] > upper_bound)]\n",
    "    \n",
    "    print(f\"\\nüîç AN√ÅLISIS DE OUTLIERS SALARIALES:\")\n",
    "    print(f\"   ‚Ä¢ Outliers detectados: {len(outliers):,} ({len(outliers)/len(df)*100:.2f}%)\")\n",
    "    print(f\"   ‚Ä¢ L√≠mite inferior: ‚Çπ{lower_bound:,.0f}\")\n",
    "    print(f\"   ‚Ä¢ L√≠mite superior: ‚Çπ{upper_bound:,.0f}\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Columna de salario no encontrada en el dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16eb75f3",
   "metadata": {},
   "source": [
    "## 6. An√°lisis de Correlaciones\n",
    "\n",
    "Exploramos las relaciones entre variables num√©ricas para identificar patrones y asociaciones importantes en los datos de RR.HH."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7af75cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar solo variables num√©ricas para an√°lisis de correlaci√≥n\n",
    "numeric_columns = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "# Remover columnas de ID si existen\n",
    "id_columns = ['employee_id', 'Employee_ID', 'ID', 'id']\n",
    "numeric_columns = [col for col in numeric_columns if col.lower() not in [id_col.lower() for id_col in id_columns]]\n",
    "\n",
    "print(f\"üìä Variables num√©ricas para an√°lisis de correlaci√≥n: {len(numeric_columns)}\")\n",
    "print(f\"   Variables: {', '.join(numeric_columns)}\")\n",
    "\n",
    "if len(numeric_columns) >= 2:\n",
    "    # Calcular matriz de correlaci√≥n\n",
    "    correlation_matrix = df[numeric_columns].corr()\n",
    "    \n",
    "    # Crear figura para visualizaci√≥n de correlaciones\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    fig.suptitle('üîó An√°lisis de Correlaciones entre Variables', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # 1. Mapa de calor completo\n",
    "    im1 = axes[0,0].imshow(correlation_matrix, cmap='RdBu_r', aspect='auto', vmin=-1, vmax=1)\n",
    "    axes[0,0].set_title('Matriz de Correlaci√≥n Completa')\n",
    "    axes[0,0].set_xticks(range(len(numeric_columns)))\n",
    "    axes[0,0].set_yticks(range(len(numeric_columns)))\n",
    "    axes[0,0].set_xticklabels(numeric_columns, rotation=45, ha='right')\n",
    "    axes[0,0].set_yticklabels(numeric_columns)\n",
    "    \n",
    "    # Agregar valores de correlaci√≥n en el mapa\n",
    "    for i in range(len(numeric_columns)):\n",
    "        for j in range(len(numeric_columns)):\n",
    "            text = axes[0,0].text(j, i, f'{correlation_matrix.iloc[i, j]:.2f}',\n",
    "                                ha=\"center\", va=\"center\", color=\"black\" if abs(correlation_matrix.iloc[i, j]) < 0.5 else \"white\",\n",
    "                                fontsize=8)\n",
    "    \n",
    "    plt.colorbar(im1, ax=axes[0,0], fraction=0.046, pad=0.04)\n",
    "    \n",
    "    # 2. Mapa de calor con seaborn (m√°s est√©tico)\n",
    "    sns.heatmap(correlation_matrix, annot=True, cmap='RdBu_r', center=0, \n",
    "                square=True, fmt='.2f', cbar_kws={\"shrink\": .8}, ax=axes[0,1])\n",
    "    axes[0,1].set_title('Matriz de Correlaci√≥n (Seaborn)')\n",
    "    axes[0,1].set_xticklabels(axes[0,1].get_xticklabels(), rotation=45, ha='right')\n",
    "    \n",
    "    # 3. Top correlaciones positivas\n",
    "    # Obtener correlaciones sin la diagonal\n",
    "    corr_pairs = []\n",
    "    for i in range(len(correlation_matrix.columns)):\n",
    "        for j in range(i+1, len(correlation_matrix.columns)):\n",
    "            corr_pairs.append({\n",
    "                'var1': correlation_matrix.columns[i],\n",
    "                'var2': correlation_matrix.columns[j],\n",
    "                'correlation': correlation_matrix.iloc[i, j]\n",
    "            })\n",
    "    \n",
    "    # Ordenar por correlaci√≥n absoluta\n",
    "    corr_pairs_df = pd.DataFrame(corr_pairs)\n",
    "    top_positive = corr_pairs_df.nlargest(10, 'correlation')\n",
    "    \n",
    "    y_pos = np.arange(len(top_positive))\n",
    "    axes[1,0].barh(y_pos, top_positive['correlation'], color='green', alpha=0.7)\n",
    "    axes[1,0].set_yticks(y_pos)\n",
    "    axes[1,0].set_yticklabels([f\"{row['var1']} vs {row['var2']}\" for _, row in top_positive.iterrows()], fontsize=8)\n",
    "    axes[1,0].set_xlabel('Correlaci√≥n')\n",
    "    axes[1,0].set_title('Top 10 Correlaciones Positivas')\n",
    "    axes[1,0].set_xlim(0, 1)\n",
    "    \n",
    "    # Agregar valores en las barras\n",
    "    for i, v in enumerate(top_positive['correlation']):\n",
    "        axes[1,0].text(v + 0.01, i, f'{v:.3f}', va='center', fontsize=8)\n",
    "    \n",
    "    # 4. Top correlaciones negativas\n",
    "    top_negative = corr_pairs_df.nsmallest(10, 'correlation')\n",
    "    \n",
    "    y_pos = np.arange(len(top_negative))\n",
    "    axes[1,1].barh(y_pos, top_negative['correlation'], color='red', alpha=0.7)\n",
    "    axes[1,1].set_yticks(y_pos)\n",
    "    axes[1,1].set_yticklabels([f\"{row['var1']} vs {row['var2']}\" for _, row in top_negative.iterrows()], fontsize=8)\n",
    "    axes[1,1].set_xlabel('Correlaci√≥n')\n",
    "    axes[1,1].set_title('Top 10 Correlaciones Negativas')\n",
    "    axes[1,1].set_xlim(-1, 0)\n",
    "    \n",
    "    # Agregar valores en las barras\n",
    "    for i, v in enumerate(top_negative['correlation']):\n",
    "        axes[1,1].text(v - 0.01, i, f'{v:.3f}', va='center', ha='right', fontsize=8)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Reporte de correlaciones significativas\n",
    "    print(f\"\\nüîç AN√ÅLISIS DE CORRELACIONES:\")\n",
    "    print(f\"\\nüìà TOP 5 CORRELACIONES POSITIVAS:\")\n",
    "    for _, row in top_positive.head().iterrows():\n",
    "        print(f\"   ‚Ä¢ {row['var1']} ‚Üî {row['var2']}: {row['correlation']:.3f}\")\n",
    "    \n",
    "    print(f\"\\nüìâ TOP 5 CORRELACIONES NEGATIVAS:\")\n",
    "    for _, row in top_negative.head().iterrows():\n",
    "        print(f\"   ‚Ä¢ {row['var1']} ‚Üî {row['var2']}: {row['correlation']:.3f}\")\n",
    "    \n",
    "    # Identificar correlaciones fuertes (|r| > 0.7)\n",
    "    strong_correlations = corr_pairs_df[abs(corr_pairs_df['correlation']) > 0.7]\n",
    "    if not strong_correlations.empty:\n",
    "        print(f\"\\nüî• CORRELACIONES FUERTES (|r| > 0.7):\")\n",
    "        for _, row in strong_correlations.iterrows():\n",
    "            print(f\"   ‚Ä¢ {row['var1']} ‚Üî {row['var2']}: {row['correlation']:.3f}\")\n",
    "    else:\n",
    "        print(f\"\\nüí° No se encontraron correlaciones fuertes (|r| > 0.7)\")\n",
    "\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Se necesitan al menos 2 variables num√©ricas para el an√°lisis de correlaci√≥n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835e7f96",
   "metadata": {},
   "source": [
    "## 7. An√°lisis de Performance y Retenci√≥n\n",
    "\n",
    "Examinamos los indicadores de desempe√±o y rotaci√≥n de personal para identificar factores cr√≠ticos en la gesti√≥n del talento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70631b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# An√°lisis de Performance y Retenci√≥n\n",
    "performance_cols = ['performance_rating', 'rating_performance', 'Performance_Rating']\n",
    "attrition_cols = ['attrition', 'renuncia', 'Attrition', 'left_company']\n",
    "\n",
    "# Identificar columnas de performance\n",
    "perf_col = None\n",
    "for col in performance_cols:\n",
    "    if col in df.columns:\n",
    "        perf_col = col\n",
    "        break\n",
    "\n",
    "# Identificar columnas de attrition/retenci√≥n\n",
    "attr_col = None\n",
    "for col in attrition_cols:\n",
    "    if col in df.columns:\n",
    "        attr_col = col\n",
    "        break\n",
    "\n",
    "print(f\"üìä An√°lisis de Performance y Retenci√≥n\")\n",
    "print(f\"   ‚Ä¢ Columna de Performance: {perf_col if perf_col else 'No encontrada'}\")\n",
    "print(f\"   ‚Ä¢ Columna de Attrition: {attr_col if attr_col else 'No encontrada'}\")\n",
    "\n",
    "# Crear figura para an√°lisis\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "fig.suptitle('üìà An√°lisis de Performance y Retenci√≥n de Empleados', fontsize=16, fontweight='bold')\n",
    "\n",
    "# 1. Distribuci√≥n de Performance Rating\n",
    "if perf_col:\n",
    "    performance_counts = df[perf_col].value_counts().sort_index()\n",
    "    colors = plt.cm.RdYlGn(np.linspace(0.2, 0.8, len(performance_counts)))\n",
    "    \n",
    "    axes[0,0].bar(performance_counts.index, performance_counts.values, color=colors, alpha=0.8, edgecolor='black')\n",
    "    axes[0,0].set_title('Distribuci√≥n de Performance Rating')\n",
    "    axes[0,0].set_xlabel('Performance Rating')\n",
    "    axes[0,0].set_ylabel('N√∫mero de Empleados')\n",
    "    \n",
    "    # Agregar porcentajes\n",
    "    total = performance_counts.sum()\n",
    "    for i, (rating, count) in enumerate(performance_counts.items()):\n",
    "        percentage = (count / total) * 100\n",
    "        axes[0,0].text(rating, count + count*0.01, f'{percentage:.1f}%', \n",
    "                      ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    # Estad√≠sticas de performance\n",
    "    perf_stats = f\"\"\"\n",
    "    üìä ESTAD√çSTICAS DE PERFORMANCE:\n",
    "    \n",
    "    Rating Promedio: {df[perf_col].mean():.2f}\n",
    "    Mediana: {df[perf_col].median():.2f}\n",
    "    Moda: {df[perf_col].mode().iloc[0] if not df[perf_col].mode().empty else 'N/A'}\n",
    "    \n",
    "    Desviaci√≥n Est√°ndar: {df[perf_col].std():.2f}\n",
    "    \n",
    "    Distribuci√≥n:\n",
    "    \"\"\"\n",
    "    for rating, count in performance_counts.items():\n",
    "        perf_stats += f\"\\n    Rating {rating}: {count:,} ({count/total*100:.1f}%)\"\n",
    "    \n",
    "    print(f\"\\n{perf_stats}\")\n",
    "else:\n",
    "    axes[0,0].text(0.5, 0.5, 'Datos de Performance\\nno disponibles', \n",
    "                   ha='center', va='center', transform=axes[0,0].transAxes, fontsize=12)\n",
    "    axes[0,0].set_title('Distribuci√≥n de Performance Rating')\n",
    "\n",
    "# 2. An√°lisis de Attrition/Retenci√≥n\n",
    "if attr_col:\n",
    "    # Convertir a formato est√°ndar si es necesario\n",
    "    if df[attr_col].dtype == 'object':\n",
    "        attrition_mapping = {'Yes': 1, 'No': 0, 'yes': 1, 'no': 0, 'YES': 1, 'NO': 0,\n",
    "                            'True': 1, 'False': 0, 'true': 1, 'false': 0,\n",
    "                            'S√≠': 1, 'No': 0, 'SI': 1, 'NO': 0}\n",
    "        df[f'{attr_col}_numeric'] = df[attr_col].map(attrition_mapping).fillna(df[attr_col])\n",
    "        attr_col_numeric = f'{attr_col}_numeric'\n",
    "    else:\n",
    "        attr_col_numeric = attr_col\n",
    "    \n",
    "    attrition_counts = df[attr_col_numeric].value_counts().sort_index()\n",
    "    labels = ['Retenido', 'Renuncia'] if len(attrition_counts) == 2 else [f'Categor√≠a {i}' for i in attrition_counts.index]\n",
    "    colors = ['#2ecc71', '#e74c3c'] if len(attrition_counts) == 2 else plt.cm.Set3(np.linspace(0, 1, len(attrition_counts)))\n",
    "    \n",
    "    wedges, texts, autotexts = axes[0,1].pie(attrition_counts.values, labels=labels, autopct='%1.1f%%', \n",
    "                                           colors=colors, startangle=90, explode=[0.05]*len(attrition_counts))\n",
    "    axes[0,1].set_title('Tasa de Retenci√≥n vs Attrition')\n",
    "    \n",
    "    # Mejorar la apariencia del texto\n",
    "    for autotext in autotexts:\n",
    "        autotext.set_color('white')\n",
    "        autotext.set_fontweight('bold')\n",
    "        autotext.set_fontsize(11)\n",
    "    \n",
    "    # Calcular m√©tricas de retenci√≥n\n",
    "    total_employees = len(df)\n",
    "    if len(attrition_counts) == 2:\n",
    "        retained = attrition_counts.get(0, 0)\n",
    "        left = attrition_counts.get(1, 0)\n",
    "        retention_rate = (retained / total_employees) * 100\n",
    "        attrition_rate = (left / total_employees) * 100\n",
    "        \n",
    "        print(f\"\\nüéØ M√âTRICAS DE RETENCI√ìN:\")\n",
    "        print(f\"   ‚Ä¢ Tasa de Retenci√≥n: {retention_rate:.1f}%\")\n",
    "        print(f\"   ‚Ä¢ Tasa de Attrition: {attrition_rate:.1f}%\")\n",
    "        print(f\"   ‚Ä¢ Empleados Retenidos: {retained:,}\")\n",
    "        print(f\"   ‚Ä¢ Empleados que Renunciaron: {left:,}\")\n",
    "else:\n",
    "    axes[0,1].text(0.5, 0.5, 'Datos de Attrition\\nno disponibles', \n",
    "                   ha='center', va='center', transform=axes[0,1].transAxes, fontsize=12)\n",
    "    axes[0,1].set_title('An√°lisis de Attrition')\n",
    "\n",
    "# 3. Performance vs Salario (si ambos est√°n disponibles)\n",
    "salary_col = 'salario_inr' if 'salario_inr' in df.columns else 'Salary_INR' if 'Salary_INR' in df.columns else None\n",
    "\n",
    "if perf_col and salary_col:\n",
    "    # Scatter plot\n",
    "    scatter = axes[0,2].scatter(df[perf_col], df[salary_col], alpha=0.6, c=df[perf_col], \n",
    "                               cmap='viridis', s=30, edgecolors='black', linewidth=0.5)\n",
    "    axes[0,2].set_title('Performance vs Salario')\n",
    "    axes[0,2].set_xlabel('Performance Rating')\n",
    "    axes[0,2].set_ylabel('Salario (INR)')\n",
    "    axes[0,2].ticklabel_format(style='scientific', axis='y', scilimits=(0,0))\n",
    "    \n",
    "    # Agregar l√≠nea de tendencia\n",
    "    z = np.polyfit(df[perf_col].dropna(), df[salary_col].dropna(), 1)\n",
    "    p = np.poly1d(z)\n",
    "    axes[0,2].plot(df[perf_col].unique(), p(df[perf_col].unique()), \"r--\", alpha=0.8, linewidth=2)\n",
    "    \n",
    "    plt.colorbar(scatter, ax=axes[0,2], fraction=0.046, pad=0.04)\n",
    "    \n",
    "    # Calcular correlaci√≥n\n",
    "    correlation = df[perf_col].corr(df[salary_col])\n",
    "    axes[0,2].text(0.05, 0.95, f'Correlaci√≥n: {correlation:.3f}', \n",
    "                   transform=axes[0,2].transAxes, bbox=dict(boxstyle=\"round\", facecolor='white', alpha=0.8))\n",
    "else:\n",
    "    axes[0,2].text(0.5, 0.5, 'Datos insuficientes para\\nPerformance vs Salario', \n",
    "                   ha='center', va='center', transform=axes[0,2].transAxes, fontsize=12)\n",
    "    axes[0,2].set_title('Performance vs Salario')\n",
    "\n",
    "# 4. Performance por Departamento\n",
    "if perf_col and ('departamento' in df.columns or 'Department' in df.columns):\n",
    "    dept_col = 'departamento' if 'departamento' in df.columns else 'Department'\n",
    "    perf_by_dept = df.groupby(dept_col)[perf_col].agg(['mean', 'count']).sort_values('mean', ascending=False)\n",
    "    \n",
    "    # Solo mostrar departamentos con m√°s de 10 empleados para relevancia estad√≠stica\n",
    "    perf_by_dept = perf_by_dept[perf_by_dept['count'] >= 10].head(15)\n",
    "    \n",
    "    bars = axes[1,0].barh(range(len(perf_by_dept)), perf_by_dept['mean'], \n",
    "                         color=plt.cm.RdYlGn(perf_by_dept['mean'] / perf_by_dept['mean'].max()),\n",
    "                         alpha=0.8, edgecolor='black')\n",
    "    axes[1,0].set_yticks(range(len(perf_by_dept)))\n",
    "    axes[1,0].set_yticklabels(perf_by_dept.index, fontsize=9)\n",
    "    axes[1,0].set_xlabel('Performance Rating Promedio')\n",
    "    axes[1,0].set_title('Performance Promedio por Departamento')\n",
    "    axes[1,0].set_xlim(0, df[perf_col].max() * 1.1)\n",
    "    \n",
    "    # Agregar valores en las barras\n",
    "    for i, (bar, value) in enumerate(zip(bars, perf_by_dept['mean'])):\n",
    "        width = bar.get_width()\n",
    "        axes[1,0].text(width + 0.01, bar.get_y() + bar.get_height()/2, \n",
    "                      f'{value:.2f}', ha='left', va='center', fontsize=8, fontweight='bold')\n",
    "else:\n",
    "    axes[1,0].text(0.5, 0.5, 'Datos insuficientes para\\nPerformance por Departamento', \n",
    "                   ha='center', va='center', transform=axes[1,0].transAxes, fontsize=12)\n",
    "    axes[1,0].set_title('Performance por Departamento')\n",
    "\n",
    "# 5. Attrition por Performance\n",
    "if perf_col and attr_col:\n",
    "    attrition_by_perf = df.groupby(perf_col)[attr_col_numeric].agg(['mean', 'count'])\n",
    "    attrition_by_perf['attrition_rate'] = attrition_by_perf['mean'] * 100\n",
    "    \n",
    "    bars = axes[1,1].bar(attrition_by_perf.index, attrition_by_perf['attrition_rate'], \n",
    "                        color='red', alpha=0.7, edgecolor='black')\n",
    "    axes[1,1].set_title('Tasa de Attrition por Performance Rating')\n",
    "    axes[1,1].set_xlabel('Performance Rating')\n",
    "    axes[1,1].set_ylabel('Tasa de Attrition (%)')\n",
    "    axes[1,1].set_ylim(0, 100)\n",
    "    \n",
    "    # Agregar valores en las barras\n",
    "    for bar, value in zip(bars, attrition_by_perf['attrition_rate']):\n",
    "        height = bar.get_height()\n",
    "        axes[1,1].text(bar.get_x() + bar.get_width()/2., height + 1,\n",
    "                      f'{value:.1f}%', ha='center', va='bottom', fontweight='bold')\n",
    "else:\n",
    "    axes[1,1].text(0.5, 0.5, 'Datos insuficientes para\\nAttrition vs Performance', \n",
    "                   ha='center', va='center', transform=axes[1,1].transAxes, fontsize=12)\n",
    "    axes[1,1].set_title('Attrition por Performance Rating')\n",
    "\n",
    "# 6. Resumen de m√©tricas clave\n",
    "axes[1,2].axis('off')\n",
    "summary_text = \"üìä RESUMEN EJECUTIVO\\n\\n\"\n",
    "\n",
    "if perf_col:\n",
    "    avg_performance = df[perf_col].mean()\n",
    "    high_performers = (df[perf_col] >= 4).sum() if df[perf_col].max() >= 4 else (df[perf_col] >= df[perf_col].quantile(0.8)).sum()\n",
    "    total_employees = len(df)\n",
    "    \n",
    "    summary_text += f\"üéØ PERFORMANCE:\\n\"\n",
    "    summary_text += f\"   Rating Promedio: {avg_performance:.2f}\\n\"\n",
    "    summary_text += f\"   Alto Rendimiento: {high_performers:,} ({high_performers/total_employees*100:.1f}%)\\n\\n\"\n",
    "\n",
    "if attr_col and len(attrition_counts) == 2:\n",
    "    summary_text += f\"üîÑ RETENCI√ìN:\\n\"\n",
    "    summary_text += f\"   Tasa Retenci√≥n: {retention_rate:.1f}%\\n\"\n",
    "    summary_text += f\"   Tasa Attrition: {attrition_rate:.1f}%\\n\\n\"\n",
    "\n",
    "if salary_col:\n",
    "    avg_salary = df[salary_col].mean()\n",
    "    summary_text += f\"üí∞ COMPENSACI√ìN:\\n\"\n",
    "    summary_text += f\"   Salario Promedio: ‚Çπ{avg_salary:,.0f}\\n\\n\"\n",
    "\n",
    "summary_text += f\"üë• TOTAL EMPLEADOS: {len(df):,}\"\n",
    "\n",
    "axes[1,2].text(0.1, 0.9, summary_text, transform=axes[1,2].transAxes, \n",
    "               fontsize=11, verticalalignment='top',\n",
    "               bbox=dict(boxstyle=\"round,pad=0.5\", facecolor=\"lightblue\", alpha=0.7))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f06880",
   "metadata": {},
   "source": [
    "## 8. Insights de Negocio y Recomendaciones\n",
    "\n",
    "Bas√°ndose en el an√°lisis exploratorio, identificamos los hallazgos clave y las recomendaciones estrat√©gicas para la gesti√≥n de RR.HH."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b096b21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar insights autom√°ticos basados en los datos analizados\n",
    "print(\"üéØ TALENT PULSE - INSIGHTS DE NEGOCIO Y RECOMENDACIONES ESTRAT√âGICAS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# 1. An√°lisis de Diversidad y Composici√≥n\n",
    "print(\"\\n1Ô∏è‚É£ DIVERSIDAD Y COMPOSICI√ìN ORGANIZACIONAL:\")\n",
    "\n",
    "# An√°lisis de g√©nero si est√° disponible\n",
    "gender_cols = ['genero', 'gender', 'Gender', 'sexo']\n",
    "gender_col = None\n",
    "for col in gender_cols:\n",
    "    if col in df.columns:\n",
    "        gender_col = col\n",
    "        break\n",
    "\n",
    "if gender_col:\n",
    "    gender_dist = df[gender_col].value_counts(normalize=True) * 100\n",
    "    print(f\"   üìä Distribuci√≥n por G√©nero:\")\n",
    "    for gender, pct in gender_dist.items():\n",
    "        print(f\"      ‚Ä¢ {gender}: {pct:.1f}%\")\n",
    "    \n",
    "    # Recomendaci√≥n de diversidad\n",
    "    min_representation = gender_dist.min()\n",
    "    if min_representation < 30:\n",
    "        print(f\"   ‚ö†Ô∏è  ALERTA: Baja representaci√≥n del g√©nero minoritario ({min_representation:.1f}%)\")\n",
    "        print(f\"   üí° RECOMENDACI√ìN: Implementar estrategias de diversidad e inclusi√≥n\")\n",
    "\n",
    "# An√°lisis departamental\n",
    "dept_cols = ['departamento', 'Department', 'department']\n",
    "dept_col = None\n",
    "for col in dept_cols:\n",
    "    if col in df.columns:\n",
    "        dept_col = col\n",
    "        break\n",
    "\n",
    "if dept_col:\n",
    "    dept_size = df[dept_col].value_counts()\n",
    "    largest_dept = dept_size.index[0]\n",
    "    largest_pct = (dept_size.iloc[0] / len(df)) * 100\n",
    "    \n",
    "    print(f\"   üè¢ Departamento m√°s grande: {largest_dept} ({largest_pct:.1f}%)\")\n",
    "    if largest_pct > 40:\n",
    "        print(f\"   ‚ö†Ô∏è  ALERTA: Concentraci√≥n alta en un departamento\")\n",
    "        print(f\"   üí° RECOMENDACI√ìN: Considerar redistribuci√≥n o crecimiento balanceado\")\n",
    "\n",
    "# 2. An√°lisis Salarial\n",
    "print(f\"\\n2Ô∏è‚É£ AN√ÅLISIS SALARIAL Y EQUIDAD:\")\n",
    "\n",
    "salary_col = 'salario_inr' if 'salario_inr' in df.columns else 'Salary_INR' if 'Salary_INR' in df.columns else None\n",
    "\n",
    "if salary_col:\n",
    "    avg_salary = df[salary_col].mean()\n",
    "    median_salary = df[salary_col].median()\n",
    "    salary_std = df[salary_col].std()\n",
    "    coefficient_variation = (salary_std / avg_salary) * 100\n",
    "    \n",
    "    print(f\"   üí∞ Salario Promedio: ‚Çπ{avg_salary:,.0f}\")\n",
    "    print(f\"   üìä Mediana Salarial: ‚Çπ{median_salary:,.0f}\")\n",
    "    print(f\"   üìà Coeficiente de Variaci√≥n: {coefficient_variation:.1f}%\")\n",
    "    \n",
    "    if coefficient_variation > 50:\n",
    "        print(f\"   ‚ö†Ô∏è  ALERTA: Alta variabilidad salarial\")\n",
    "        print(f\"   üí° RECOMENDACI√ìN: Revisar estructura de compensaciones\")\n",
    "    \n",
    "    # An√°lisis de equidad salarial por g√©nero\n",
    "    if gender_col and len(df[gender_col].unique()) == 2:\n",
    "        salary_by_gender = df.groupby(gender_col)[salary_col].mean()\n",
    "        gender_gap = abs(salary_by_gender.iloc[0] - salary_by_gender.iloc[1]) / salary_by_gender.max() * 100\n",
    "        \n",
    "        print(f\"   ‚öñÔ∏è Brecha Salarial por G√©nero: {gender_gap:.1f}%\")\n",
    "        if gender_gap > 10:\n",
    "            print(f\"   ‚ö†Ô∏è  ALERTA: Brecha salarial significativa\")\n",
    "            print(f\"   üí° RECOMENDACI√ìN: Auditor√≠a de equidad salarial\")\n",
    "\n",
    "# 3. An√°lisis de Performance\n",
    "print(f\"\\n3Ô∏è‚É£ AN√ÅLISIS DE RENDIMIENTO:\")\n",
    "\n",
    "perf_cols = ['performance_rating', 'rating_performance', 'Performance_Rating']\n",
    "perf_col = None\n",
    "for col in perf_cols:\n",
    "    if col in df.columns:\n",
    "        perf_col = col\n",
    "        break\n",
    "\n",
    "if perf_col:\n",
    "    avg_performance = df[perf_col].mean()\n",
    "    perf_std = df[perf_col].std()\n",
    "    \n",
    "    # Definir alto rendimiento (top 20% o rating >= 4)\n",
    "    if df[perf_col].max() >= 4:\n",
    "        high_performers = (df[perf_col] >= 4).sum()\n",
    "        low_performers = (df[perf_col] <= 2).sum()\n",
    "    else:\n",
    "        high_performers = (df[perf_col] >= df[perf_col].quantile(0.8)).sum()\n",
    "        low_performers = (df[perf_col] <= df[perf_col].quantile(0.2)).sum()\n",
    "    \n",
    "    high_perf_pct = (high_performers / len(df)) * 100\n",
    "    low_perf_pct = (low_performers / len(df)) * 100\n",
    "    \n",
    "    print(f\"   üéØ Performance Promedio: {avg_performance:.2f}\")\n",
    "    print(f\"   ‚≠ê Alto Rendimiento: {high_performers:,} empleados ({high_perf_pct:.1f}%)\")\n",
    "    print(f\"   ‚ö†Ô∏è Bajo Rendimiento: {low_performers:,} empleados ({low_perf_pct:.1f}%)\")\n",
    "    \n",
    "    if low_perf_pct > 15:\n",
    "        print(f\"   üö® ALERTA: Alto porcentaje de bajo rendimiento\")\n",
    "        print(f\"   üí° RECOMENDACI√ìN: Programa de mejora de performance\")\n",
    "\n",
    "# 4. An√°lisis de Retenci√≥n\n",
    "print(f\"\\n4Ô∏è‚É£ AN√ÅLISIS DE RETENCI√ìN:\")\n",
    "\n",
    "attr_cols = ['attrition', 'renuncia', 'Attrition', 'left_company']\n",
    "attr_col = None\n",
    "for col in attr_cols:\n",
    "    if col in df.columns:\n",
    "        attr_col = col\n",
    "        break\n",
    "\n",
    "if attr_col:\n",
    "    # Calcular tasa de attrition\n",
    "    if df[attr_col].dtype == 'object':\n",
    "        attrition_rate = (df[attr_col].str.lower().isin(['yes', 's√≠', 'true', '1'])).mean() * 100\n",
    "    else:\n",
    "        attrition_rate = df[attr_col].mean() * 100\n",
    "    \n",
    "    retention_rate = 100 - attrition_rate\n",
    "    \n",
    "    print(f\"   üîÑ Tasa de Retenci√≥n: {retention_rate:.1f}%\")\n",
    "    print(f\"   üö™ Tasa de Attrition: {attrition_rate:.1f}%\")\n",
    "    \n",
    "    if attrition_rate > 15:\n",
    "        print(f\"   üö® ALERTA: Alta tasa de rotaci√≥n\")\n",
    "        print(f\"   üí° RECOMENDACI√ìN: Investigar causas de rotaci√≥n\")\n",
    "    elif attrition_rate < 5:\n",
    "        print(f\"   ‚úÖ EXCELENTE: Baja rotaci√≥n de personal\")\n",
    "\n",
    "# 5. Correlaciones Clave\n",
    "print(f\"\\n5Ô∏è‚É£ CORRELACIONES CLAVE:\")\n",
    "\n",
    "numeric_columns = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "id_columns = ['employee_id', 'Employee_ID', 'ID', 'id']\n",
    "numeric_columns = [col for col in numeric_columns if col.lower() not in [id_col.lower() for id_col in id_columns]]\n",
    "\n",
    "if len(numeric_columns) >= 2:\n",
    "    correlation_matrix = df[numeric_columns].corr()\n",
    "    \n",
    "    # Encontrar las correlaciones m√°s fuertes\n",
    "    strong_correlations = []\n",
    "    for i in range(len(correlation_matrix.columns)):\n",
    "        for j in range(i+1, len(correlation_matrix.columns)):\n",
    "            corr_value = correlation_matrix.iloc[i, j]\n",
    "            if abs(corr_value) > 0.5:  # Correlaciones moderadas o fuertes\n",
    "                strong_correlations.append({\n",
    "                    'var1': correlation_matrix.columns[i],\n",
    "                    'var2': correlation_matrix.columns[j],\n",
    "                    'correlation': corr_value\n",
    "                })\n",
    "    \n",
    "    if strong_correlations:\n",
    "        print(f\"   üîó Correlaciones Significativas Encontradas:\")\n",
    "        for corr in sorted(strong_correlations, key=lambda x: abs(x['correlation']), reverse=True)[:5]:\n",
    "            direction = \"positiva\" if corr['correlation'] > 0 else \"negativa\"\n",
    "            print(f\"      ‚Ä¢ {corr['var1']} ‚Üî {corr['var2']}: {corr['correlation']:.3f} ({direction})\")\n",
    "\n",
    "# 6. Recomendaciones Estrat√©gicas\n",
    "print(f\"\\n6Ô∏è‚É£ RECOMENDACIONES ESTRAT√âGICAS:\")\n",
    "\n",
    "recommendations = []\n",
    "\n",
    "# Recomendaciones basadas en size\n",
    "total_employees = len(df)\n",
    "if total_employees < 100:\n",
    "    recommendations.append(\"üìà Considerar plan de crecimiento organizacional estructurado\")\n",
    "elif total_employees > 10000:\n",
    "    recommendations.append(\"üèóÔ∏è Implementar sistemas de gesti√≥n escalables\")\n",
    "\n",
    "# Recomendaciones de datos\n",
    "missing_data_pct = df.isnull().sum().sum() / (len(df) * len(df.columns)) * 100\n",
    "if missing_data_pct > 10:\n",
    "    recommendations.append(\"üîç Mejorar la calidad y completitud de los datos de RR.HH.\")\n",
    "\n",
    "# Recomendaciones espec√≠ficas\n",
    "if salary_col and coefficient_variation > 50:\n",
    "    recommendations.append(\"üí∞ Establecer bandas salariales m√°s estructuradas\")\n",
    "\n",
    "if perf_col and low_perf_pct > 15:\n",
    "    recommendations.append(\"üéØ Implementar programa de desarrollo de performance\")\n",
    "\n",
    "if attr_col and attrition_rate > 15:\n",
    "    recommendations.append(\"üîÑ Desarrollar estrategia de retenci√≥n de talento\")\n",
    "\n",
    "# Recomendaciones generales\n",
    "recommendations.extend([\n",
    "    \"üìä Implementar dashboards de m√©tricas de RR.HH. en tiempo real\",\n",
    "    \"ü§ñ Considerar modelos predictivos para attrition y performance\",\n",
    "    \"üìã Establecer KPIs regulares de seguimiento organizacional\",\n",
    "    \"üéì Desarrollar programas de carrera y desarrollo profesional\"\n",
    "])\n",
    "\n",
    "for i, rec in enumerate(recommendations, 1):\n",
    "    print(f\"   {i}. {rec}\")\n",
    "\n",
    "print(f\"\\n\" + \"=\"*80)\n",
    "print(f\"üìà RESUMEN EJECUTIVO: Dataset analizado con {len(df):,} empleados\")\n",
    "print(f\"üîç An√°lisis completado con {len(df.columns)} variables\")\n",
    "print(f\"üìÖ Timestamp del an√°lisis: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dcb6f00",
   "metadata": {},
   "source": [
    "## 9. Conclusiones y Pr√≥ximos Pasos\n",
    "\n",
    "Este an√°lisis exploratorio proporciona una base s√≥lida para la toma de decisiones estrat√©gicas en gesti√≥n de talento y desarrollo organizacional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480fb3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conclusiones finales del an√°lisis\n",
    "print(\"üéØ TALENT PULSE - CONCLUSIONES Y PR√ìXIMOS PASOS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Resumen de lo que se analiz√≥\n",
    "print(\"\\n‚úÖ AN√ÅLISIS COMPLETADO:\")\n",
    "print(\"   1. Carga y exploraci√≥n inicial de datos\")\n",
    "print(\"   2. An√°lisis estad√≠stico descriptivo\")\n",
    "print(\"   3. An√°lisis departamental y organizacional\")\n",
    "print(\"   4. Evaluaci√≥n salarial y equidad\")\n",
    "print(\"   5. An√°lisis de correlaciones\")\n",
    "print(\"   6. Evaluaci√≥n de performance y retenci√≥n\")\n",
    "print(\"   7. Generaci√≥n de insights de negocio\")\n",
    "\n",
    "# M√©tricas clave del dataset\n",
    "print(f\"\\nüìä M√âTRICAS CLAVE DEL DATASET:\")\n",
    "print(f\"   ‚Ä¢ Total de empleados analizados: {len(df):,}\")\n",
    "print(f\"   ‚Ä¢ Variables disponibles: {len(df.columns)}\")\n",
    "print(f\"   ‚Ä¢ Completitud de datos: {((1 - df.isnull().sum().sum() / (len(df) * len(df.columns))) * 100):.1f}%\")\n",
    "\n",
    "# Variables principales identificadas\n",
    "numeric_vars = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical_vars = df.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "print(f\"   ‚Ä¢ Variables num√©ricas: {len(numeric_vars)}\")\n",
    "print(f\"   ‚Ä¢ Variables categ√≥ricas: {len(categorical_vars)}\")\n",
    "\n",
    "# Pr√≥ximos pasos recomendados\n",
    "print(f\"\\nüöÄ PR√ìXIMOS PASOS RECOMENDADOS:\")\n",
    "\n",
    "print(f\"\\n   üìà AN√ÅLISIS AVANZADO:\")\n",
    "print(f\"   1. Segmentaci√≥n de empleados (clustering)\")\n",
    "print(f\"   2. An√°lisis de series temporales (si hay datos hist√≥ricos)\")\n",
    "print(f\"   3. An√°lisis de supervivencia para retenci√≥n\")\n",
    "print(f\"   4. An√°lisis de redes organizacionales\")\n",
    "\n",
    "print(f\"\\n   ü§ñ MODELOS PREDICTIVOS:\")\n",
    "print(f\"   1. Predicci√≥n de attrition/renuncia\")\n",
    "print(f\"   2. Predicci√≥n de performance rating\")\n",
    "print(f\"   3. Optimizaci√≥n salarial\")\n",
    "print(f\"   4. Identificaci√≥n de empleados en riesgo\")\n",
    "\n",
    "print(f\"\\n   üìä DASHBOARD Y REPORTING:\")\n",
    "print(f\"   1. Dashboard ejecutivo interactivo\")\n",
    "print(f\"   2. Reportes autom√°ticos mensuales\")\n",
    "print(f\"   3. Alertas de m√©tricas cr√≠ticas\")\n",
    "print(f\"   4. An√°lisis comparativo temporal\")\n",
    "\n",
    "print(f\"\\n   üéØ ACCIONES OPERATIVAS:\")\n",
    "print(f\"   1. Definir KPIs de RR.HH.\")\n",
    "print(f\"   2. Establecer benchmarks internos\")\n",
    "print(f\"   3. Crear planes de acci√≥n espec√≠ficos\")\n",
    "print(f\"   4. Implementar sistema de seguimiento\")\n",
    "\n",
    "# Valor del an√°lisis\n",
    "print(f\"\\nüí° VALOR GENERADO POR ESTE AN√ÅLISIS:\")\n",
    "print(f\"   ‚Ä¢ Comprensi√≥n profunda de la composici√≥n organizacional\")\n",
    "print(f\"   ‚Ä¢ Identificaci√≥n de oportunidades de mejora\")\n",
    "print(f\"   ‚Ä¢ Base de datos para decisiones estrat√©gicas\")\n",
    "print(f\"   ‚Ä¢ Framework para an√°lisis futuros\")\n",
    "print(f\"   ‚Ä¢ Detecci√≥n de riesgos y alertas tempranas\")\n",
    "\n",
    "# Contacto y soporte\n",
    "print(f\"\\nüìß SOPORTE T√âCNICO:\")\n",
    "print(f\"   ‚Ä¢ Para dudas sobre el an√°lisis: equipo-analytics@empresa.com\")\n",
    "print(f\"   ‚Ä¢ Para nuevos requerimientos: rrhh-data@empresa.com\")\n",
    "print(f\"   ‚Ä¢ Documentaci√≥n completa: /docs/analytics/hr-dashboard\")\n",
    "\n",
    "print(f\"\\n\" + \"=\"*70)\n",
    "print(f\"üèÜ AN√ÅLISIS COMPLETADO EXITOSAMENTE\")\n",
    "print(f\"üìÖ Fecha: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"üë®‚Äçüíº Analista: TalentPulse Analytics Engine\")\n",
    "print(f\"üîÑ Versi√≥n: 1.0\")\n",
    "print(f\"=\"*70)\n",
    "\n",
    "# Guardar resumen en archivo de texto (opcional)\n",
    "try:\n",
    "    summary_path = \"../reports/eda_summary_report.txt\"\n",
    "    with open(summary_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(f\"TALENT PULSE - REPORTE DE AN√ÅLISIS EXPLORATORIO\\n\")\n",
    "        f.write(f\"{'='*60}\\n\\n\")\n",
    "        f.write(f\"Fecha del an√°lisis: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "        f.write(f\"Dataset analizado: {len(df):,} empleados\\n\")\n",
    "        f.write(f\"Variables analizadas: {len(df.columns)}\\n\\n\")\n",
    "        f.write(\"Este an√°lisis proporcion√≥ insights clave para la gesti√≥n estrat√©gica de RR.HH.\\n\")\n",
    "        f.write(\"Consulte el notebook completo para detalles espec√≠ficos y visualizaciones.\\n\")\n",
    "    print(f\"\\nüìÅ Resumen guardado en: {summary_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ö†Ô∏è No se pudo guardar el resumen: {str(e)}\")\n",
    "\n",
    "print(f\"\\nüéâ ¬°Gracias por usar TalentPulse Analytics!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
